{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "import random\n",
    "from utils import plot_samples_with_labels, classify, plot_conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the MNIST dataset (handwritten digit images with labels)\n",
    "mnist = keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples_with_labels(training_images, training_labels, num_samples = 25, cmap = plt.cm.binary, randomize= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Reshape the data to include a channel dimension\n",
    "training_images = training_images.reshape(training_images.shape[0], 28, 28, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),  # 1 = grayscale\n",
    "    Dense(units=50, activation='relu', input_shape=(28, 28, 1)),\n",
    "    Dense(units=50, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "num_training_images = training_images.shape[0]\n",
    "\n",
    "history = model.fit(\n",
    "    training_images, training_labels,\n",
    "    epochs=10,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(training_images, training_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/digit_non_CNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the model to classify new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_non_cnn = load_model('models/digit_non_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(test_images, model):\n",
    "    \"\"\"\n",
    "    Predicts the class labels for a batch of test images using a trained model.\n",
    "\n",
    "    Args:\n",
    "        test_images (numpy.ndarray): Preprocessed test images ready for prediction.\n",
    "        model (tensorflow.keras.Model): A trained model to classify the images.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: An array of predicted class labels.\n",
    "    \"\"\"\n",
    "    predictions = model.predict(test_images)    # Predict probabilities\n",
    "    predicted_class = np.argmax(predictions, axis=-1)    # Get class with highest probability\n",
    "    return predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = classify(test_images, model_non_cnn)\n",
    "predicted_labels = np.array(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples_with_labels(test_images, test_labels, predicted_labels, num_samples = 10, randomize= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"Accuracy:\", accuracy_score(test_labels, predicted_labels))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "plot_conf_matrix(test_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some misclassified images\n",
    "\n",
    "misclassified_indices = (test_labels != predicted_labels)\n",
    "misclassified_images = test_images[misclassified_indices]\n",
    "misclassified_true_labels = test_labels[misclassified_indices]\n",
    "misclassified_predicted_labels = predicted_labels [misclassified_indices]\n",
    "\n",
    "if len(misclassified_images) > 0:\n",
    "    plot_samples_with_labels(misclassified_images, misclassified_true_labels, misclassified_predicted_labels, num_samples = 10, randomize= True)\n",
    "else:\n",
    "    print(\"No misclassified images found in the selected batch.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qué dificultades encuentra nuestro modelo?\n",
    "\n",
    "Ideas para solucionarlas?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo tiene una arquitectura simple, utiliza únicamente capas densas y aplanadas (Fully Connected Layers) para procesar imágenes, lo que ignora la información espacial inherente a las imágenes (como bordes, patrones y texturas).\n",
    "\n",
    "El modelo se entrena y valida con los mismos datos de entrenamiento, lo que provoca sobreajuste.\n",
    "La precisión del modelo es alta en los datos de entrenamiento, pero podría no generalizar bien en datos no vistos.\n",
    "\n",
    "No se han aplicado técnicas como Dropout o Batch Normalization, lo que hace que el modelo sea más propenso al sobreajuste.\n",
    "\n",
    "Algunas imágenes del conjunto de datos pueden ser difíciles de clasificar debido a escritura poco clara o mal formada.\n",
    "\n",
    "Este modelo tiene limitaciones al enfrentarse a problemas más complejos como imágenes a color o conjuntos de datos más grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Configurar semilla para reproducibilidad\n",
    "np.random.seed(42)\n",
    "\n",
    "# Cargar datos MNIST\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Visualizar ejemplos del conjunto de datos\n",
    "def plot_samples(images, labels, num_samples=25, cmap='gray'):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i], cmap=cmap)\n",
    "        plt.xlabel(labels[i])\n",
    "    plt.show()\n",
    "\n",
    "plot_samples(training_images, training_labels)\n",
    "\n",
    "# **Preprocesamiento de los datos**\n",
    "# Normalizar las imágenes al rango [0, 1]\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Añadir dimensión de canal (grayscale)\n",
    "training_images = training_images.reshape(training_images.shape[0], 28, 28, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
    "\n",
    "# Separar un conjunto de validación del conjunto de entrenamiento\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    training_images, training_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# **Aumento de datos**\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# **Construcción del modelo CNN**\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  # Regularización para evitar sobreajuste\n",
    "    Dense(10, activation='softmax')  # 10 clases (0-9)\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "cnn_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Mostrar resumen del modelo\n",
    "cnn_model.summary()\n",
    "\n",
    "# **Entrenamiento del modelo**\n",
    "history = cnn_model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=32),\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(X_train) // 32\n",
    ")\n",
    "\n",
    "# **Evaluar el modelo en el conjunto de prueba**\n",
    "test_loss, test_accuracy = cnn_model.evaluate(test_images, test_labels)\n",
    "print(f'\\nPérdida en prueba: {test_loss:.4f}')\n",
    "print(f'Precisión en prueba: {test_accuracy:.2%}')\n",
    "\n",
    "# **Matriz de confusión y reporte de clasificación**\n",
    "y_pred = np.argmax(cnn_model.predict(test_images), axis=-1)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_labels, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "conf_matrix = confusion_matrix(test_labels, y_pred)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(conf_matrix, cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# **Visualizar ejemplos mal clasificados**\n",
    "misclassified_indices = np.where(test_labels != y_pred)[0]\n",
    "misclassified_images = test_images[misclassified_indices]\n",
    "misclassified_true_labels = test_labels[misclassified_indices]\n",
    "misclassified_predicted_labels = y_pred[misclassified_indices]\n",
    "\n",
    "def plot_misclassified(images, true_labels, predicted_labels, num_samples=10):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i].reshape(28, 28), cmap='gray')\n",
    "        plt.xlabel(f'True: {true_labels[i]}, Pred: {predicted_labels[i]}')\n",
    "    plt.show()\n",
    "\n",
    "if len(misclassified_images) > 0:\n",
    "    plot_misclassified(misclassified_images, misclassified_true_labels, misclassified_predicted_labels)\n",
    "else:\n",
    "    print(\"No misclassified images found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
