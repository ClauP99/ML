{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Feature Sensitivity Analysis**\n",
    "\n",
    "#### Resumen\n",
    "La sensibilidad de características  evalúa el impacto de cada característica en la predicción del modelo al modificarla. Si cambias el valor de una característica y el modelo produce una predicción diferente, eso indica que esa característica tiene un gran impacto en el resultado. Es como hacer una prueba de resistencia para ver qué características son más sensibles a cambios. Esta técnica funciona bien con modelos de caja negra porque no requiere entender cómo funciona el modelo internamente; solo necesitas analizar cómo cambia la predicción cuando modificas las características.\n",
    "\n",
    "Para una muestra específica del conjunto de datos, modifica una característica y mide cómo cambia la predicción del modelo.\n",
    "Si al modificar una característica, el modelo cambia significativamente su predicción, entonces esa característica tiene una alta sensibilidad y, por lo tanto, una gran influencia sobre el resultado.\n",
    "Puedes usar esta técnica para identificar qué características son más importantes para el modelo en su conjunto y cuáles pueden no ser tan relevantes.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### Principios del Análisis de Sensibilidad\n",
    "\n",
    "El análisis se basa en alterar los valores de una característica específica mientras se mantienen las demás constantes. Posteriormente, se evalúa cómo varían las predicciones del modelo debido a estos cambios. Si el cambio en los valores de una característica produce una alteración significativa en las predicciones, se concluye que esa característica tiene un impacto considerable en el modelo.\n",
    "\n",
    "El cálculo puede formalizarse como sigue:\n",
    "\n",
    "1. Se obtiene el desempeño inicial del modelo en un conjunto de prueba (p. ej., error cuadrático medio, precisión, etc.).\n",
    "2. Se transforma una característica específica aplicando alguna de las técnicas descritas más adelante.\n",
    "3. Se evalúa el modelo con las características transformadas.\n",
    "4. La sensibilidad se define como la diferencia en el desempeño del modelo antes y después de la transformación.\n",
    "\n",
    "#### Métodos de Transformación\n",
    "\n",
    "El impacto de cada característica puede medirse aplicando diferentes tipos de transformaciones. Los métodos más comunes son:\n",
    "\n",
    "1. **Distribución uniforme**: Se reemplaza el valor de una característica por otro seleccionado de manera aleatoria dentro de su rango de valores posibles. Este método da igual peso a todos los valores posibles de la característica, pero puede sobreestimar la sensibilidad en caso de que los valores más comunes tengan un efecto menor en el modelo.\n",
    "\n",
    "2. **Permutación**: Los valores de la característica se reorganizan aleatoriamente según su distribución en los datos. Este enfoque considera la distribución real de los valores en los datos, lo que lo hace robusto para características sesgadas.\n",
    "\n",
    "3. **Simulación de valores faltantes**: Se intenta simular la ausencia de una característica. Por ejemplo:\n",
    "   - Sustituir los valores numéricos por su media.\n",
    "   - Reemplazar valores categóricos por una nueva clase.\n",
    "   - Usar el valor más frecuente en lugar del original.\n",
    "\n",
    "#### Consideraciones en Producción\n",
    "\n",
    "El análisis de sensibilidad puede ser computacionalmente costoso, ya que requiere múltiples predicciones, especialmente en conjuntos de datos grandes o con muchas características. Para optimizar su uso en producción, se pueden implementar las siguientes estrategias:\n",
    "\n",
    "- **Submuestreo**: Utilizar un subconjunto representativo de los datos para reducir la cantidad de predicciones necesarias.\n",
    "- **Paralelización**: Ejecutar las predicciones de manera simultánea, aprovechando múltiples procesadores o núcleos.\n",
    "- **Análisis por etapas**: Inicialmente calcular sensibilidades aproximadas con pocos datos, y luego refinar los resultados para las características más relevantes.\n",
    "\n",
    "#### Aplicaciones Prácticas\n",
    "\n",
    "El análisis de sensibilidad permite:\n",
    "- Identificar características clave que explican el comportamiento del modelo.\n",
    "- Detectar características con baja relevancia para eliminarlas y simplificar el modelo.\n",
    "- Identificar fugas de datos (leakage) cuando una característica tiene un impacto inesperadamente alto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Partial Dependence Plots (PDP)**\n",
    "\n",
    "#### Resumen\n",
    "\n",
    "Los PDP ermiten visualizar la relación entre una característica y la predicción de un modelo, manteniendo constantes las otras características. Esto es útil para entender cómo una sola característica afecta al modelo. Por ejemplo, en un modelo que predice el precio de una casa en función de varias características (tamaño, ubicación, número de habitaciones, etc.). Un PDP muestra cómo cambia la predicción del modelo a medida que varía el valor de una característica, mientras que las demás características se mantienen fijas. Este enfoque te permite ver cómo una sola variable influye en la salida, de una forma más sencilla de interpretar que el comportamiento general de un modelo complejo.\n",
    "\n",
    "Para realizarlo primero se calcula la predicción promedio del modelo para diferentes valores de una característica específica, manteniendo fijas las demás características. Con estos datos se grafica esta relación, mostrando cómo la predicción del modelo varía a medida que cambia la característica.\n",
    "\n",
    "Esto permite visualizar tendencias o patrones en la relación entre una característica y la predicción, ayudando a entender cómo el modelo responde a diferentes valores de esa variable.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### Principios de Funcionamiento\n",
    "\n",
    "El PDP calcula las predicciones promedio del modelo cuando una o varias características cambian, mientras que las demás se mantienen constantes. Formalmente, para una característica x_i, el gráfico se construye evaluando la expectativa. \n",
    "El resultado muestra cómo varían las predicciones promedio del modelo a medida que x_i toma diferentes valores, manteniendo las otras características en sus valores observados.\n",
    "\n",
    "#### Ventajas de los PDP\n",
    "\n",
    "- **Intuitivos**: Ofrecen una representación visual clara de las relaciones entre características y predicciones.\n",
    "- **Flexibles**: Pueden aplicarse a cualquier tipo de modelo, incluyendo cajas negras.\n",
    "- **Multivariables**: Permiten estudiar interacciones entre dos características mediante gráficos tridimensionales.\n",
    "\n",
    "#### Limitaciones de los PDP\n",
    "\n",
    "- **Dependencia de características**: Los PDP asumen independencia entre las características de entrada, lo que puede no ser realista en algunos conjuntos de datos. Si existe una fuerte correlación entre las características, el gráfico puede ser engañoso.\n",
    "- **Costo computacional**: Requiere múltiples evaluaciones del modelo, especialmente en conjuntos de datos grandes.\n",
    "- **Dificultad en datos categóricos**: Aunque es posible generar PDP para características categóricas, interpretar sus resultados puede ser más complicado.\n",
    "\n",
    "#### Aplicaciones Prácticas\n",
    "\n",
    "1. **Detección de relaciones no lineales**: Los PDP pueden revelar tendencias, como si un aumento en una característica genera un efecto positivo o negativo en la predicción.\n",
    "   \n",
    "2. **Identificación de puntos de saturación**: Permiten identificar valores de una característica a partir de los cuales su efecto en el modelo es insignificante.\n",
    "\n",
    "3. **Análisis de interacciones**: Los gráficos bivariados muestran cómo las combinaciones de valores de dos características afectan las predicciones.\n",
    "\n",
    "#### Casos de Uso Ejemplares\n",
    "\n",
    "- **Modelos de riesgo crediticio**: Un PDP puede mostrar cómo la edad o el historial crediticio impactan en la probabilidad de otorgar un préstamo.\n",
    "- **Modelos de predicción de salud**: Ayudan a entender cómo factores como la presión arterial o el índice de masa corporal influyen en la probabilidad de desarrollar una enfermedad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. LIME (Local Interpretable Model-agnostic Explanations)**\n",
    "\n",
    "#### Resumen\n",
    "\n",
    "LIME se enfoca en la \"localidad\" de las predicciones de los modelos de caja negra, es decir, busca entender cómo un modelo toma decisiones en casos específicos. Teniendo un modelo que hace predicciones muy complejas, como una red neuronal profunda, se puede usar para saber cómo se llegó a una conclusión para un ejemplo particular, por ejemplo, si una persona es aceptada o no para un crédito. LIME hace lo siguiente: crea un modelo simple y comprensible (como una regresión lineal) que imite el comportamiento del modelo complejo, pero solo alrededor de ese caso en particular. La idea es que aunque el modelo completo sea complicado, el comportamiento en una vecindad pequeña de un dato puede ser aproximado por un modelo simple y fácil de entender.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### Principios de Funcionamiento\n",
    "\n",
    "LIME construye un modelo explicativo simple y local alrededor de una predicción individual. La idea central es que mientras un modelo complejo puede ser difícil de interpretar en su totalidad, su comportamiento alrededor de una instancia específica puede aproximarse con un modelo más simple, como una regresión lineal.\n",
    "\n",
    "El proceso se realiza en los siguientes pasos:\n",
    "\n",
    "1. **Generación de datos locales**: \n",
    "   - Se perturban las entradas originales generando muestras artificiales cercanas a la instancia de interés.\n",
    "   - Estas perturbaciones permiten estudiar cómo cambia la predicción del modelo con ligeros ajustes en las características.\n",
    "\n",
    "2. **Predicción en datos perturbados**:\n",
    "   - Se evalúa el modelo complejo en las muestras generadas para obtener las predicciones correspondientes.\n",
    "\n",
    "3. **Ajuste del modelo explicativo**:\n",
    "   - Se entrena un modelo interpretable (como una regresión lineal o un árbol de decisión pequeño) sobre las muestras perturbadas y sus predicciones.\n",
    "   - Se asignan pesos mayores a las muestras más cercanas a la instancia original, asegurando que el modelo sea localmente representativo.\n",
    "\n",
    "4. **Interpretación**:\n",
    "   - Los coeficientes del modelo explicativo indican la importancia de cada característica en la predicción de la instancia específica.\n",
    "\n",
    "#### Ventajas de LIME\n",
    "\n",
    "- **Modelo-agnóstico**: Funciona con cualquier tipo de modelo de aprendizaje automático.\n",
    "- **Explicaciones locales**: Se centra en la instancia específica, lo que permite entender por qué se tomó una decisión particular.\n",
    "- **Flexible**: Soporta tanto datos tabulares como texto e imágenes.\n",
    "\n",
    "#### Limitaciones de LIME\n",
    "\n",
    "1. **Dependencia del muestreo**:\n",
    "   - La calidad de las explicaciones depende del conjunto de datos perturbados generado.\n",
    "   - Un muestreo pobre puede llevar a explicaciones poco precisas.\n",
    "\n",
    "2. **Inestabilidad**:\n",
    "   - Las explicaciones pueden variar significativamente para la misma instancia dependiendo de las perturbaciones y los pesos asignados.\n",
    "\n",
    "3. **Costo computacional**:\n",
    "   - Generar muestras perturbadas y realizar predicciones múltiples puede ser computacionalmente costoso, especialmente para modelos grandes.\n",
    "\n",
    "4. **Explicaciones aproximadas**:\n",
    "   - LIME asume linealidad en la vecindad de la instancia, lo que puede no ser válido si el modelo subyacente es altamente no lineal.\n",
    "\n",
    "#### Aplicaciones Prácticas\n",
    "\n",
    "- **Sistemas de recomendación**:\n",
    "   - Para entender por qué un producto o contenido específico fue recomendado a un usuario.\n",
    "- **Diagnósticos médicos**:\n",
    "   - Explica por qué un modelo predice que un paciente podría estar en riesgo de una enfermedad específica.\n",
    "- **Finanzas**:\n",
    "   - Justifica por qué un cliente recibe una calificación crediticia determinada.\n",
    "\n",
    "#### Casos de Uso Ejemplares\n",
    "\n",
    "1. **Clasificación de texto**:\n",
    "   - En problemas de análisis de sentimientos, LIME puede identificar palabras o frases específicas que influyen en la predicción.\n",
    "\n",
    "2. **Visión por computadora**:\n",
    "   - LIME puede resaltar regiones de una imagen que fueron más influyentes en la clasificación.\n",
    "\n",
    "3. **Fraude financiero**:\n",
    "   - Explica por qué una transacción en particular fue marcada como fraudulenta, ayudando a los analistas a validar o refutar la predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. SHAP (SHapley Additive exPlanations)**\n",
    "\n",
    "#### Resumen\n",
    "\n",
    "SHAP se basa en la teoría de juegos y la idea de \"justicia\" en la asignación de responsabilidades. Imagina que tienes varias personas trabajando en un proyecto y quieres saber cómo contribuye cada persona al resultado final. SHAP hace algo similar, pero en lugar de personas, estamos hablando de características del modelo y de cómo cada una contribuye a la predicción final. Para cada característica, SHAP calcula su \"contribución marginal\", es decir, cuánto cambia la predicción cuando esa característica se agrega al modelo, en combinación con las otras características. La ventaja es que SHAP no solo calcula el valor de una característica en particular, sino que tiene en cuenta todas las interacciones entre ellas, proporcionando una explicación más precisa y justa.\n",
    "\n",
    "Para esto se descompone la predicción de un modelo en contribuciones individuales de cada característica. Se calcula la \"contribución marginal\" de cada característica, es decir, cómo cambia la predicción al agregar o quitar esa característica, considerando todas las combinaciones posibles con las demás. Se asigna un valor justo (Shapley value) a cada característica, que refleja su importancia para la predicción, basado en cómo cambia la salida del modelo cuando se incluyen o excluyen esas características en diferentes combinaciones.\n",
    "\n",
    "---\n",
    "\n",
    "#### Principios de Funcionamiento\n",
    "\n",
    "El método SHAP se basa en los valores de Shapley, que son calculados considerando todas las combinaciones posibles de características y evaluando su contribución marginal. Aunque esta aproximación puede ser costosa en términos computacionales, SHAP introduce algoritmos eficientes para reducir esta carga en modelos comunes.\n",
    "\n",
    "1. **Contribución marginal**:\n",
    "   - Para una característica específica \\(i\\), su contribución marginal se calcula observando cómo cambia la predicción del modelo al incluir \\(i\\) en diferentes subconjuntos de características.\n",
    "\n",
    "2. **Distribución justa**:\n",
    "   - Los valores de Shapley aseguran que cada característica reciba una contribución proporcional a su impacto promedio en todas las combinaciones posibles.\n",
    "\n",
    "3. **Descomposición aditiva**:\n",
    "   - Las predicciones del modelo se descomponen en la suma de las contribuciones individuales de las características más un valor base, que representa la predicción promedio del modelo.\n",
    "   \n",
    "\n",
    "#### Ventajas de SHAP\n",
    "\n",
    "1. **Consistencia**:\n",
    "   - Si se incrementa la contribución marginal de una característica en un modelo, su valor SHAP nunca disminuye.\n",
    "\n",
    "2. **Atribución justa**:\n",
    "   - Los valores SHAP aseguran que todas las características sean tratadas equitativamente al considerar todas las combinaciones posibles.\n",
    "\n",
    "3. **Modelo-agnóstico**:\n",
    "   - Se puede aplicar a cualquier tipo de modelo, desde regresiones lineales hasta redes neuronales profundas.\n",
    "\n",
    "4. **Interpretación global y local**:\n",
    "   - Los valores SHAP pueden usarse para analizar la importancia de las características a nivel global (sobre un conjunto de datos) o local (para una predicción específica).\n",
    "\n",
    "\n",
    "#### Limitaciones de SHAP\n",
    "\n",
    "1. **Costo computacional**:\n",
    "   - Calcular valores SHAP exactos es costoso, ya que requiere evaluar el modelo en todas las combinaciones posibles de características.\n",
    "\n",
    "2. **Sensibilidad a correlaciones**:\n",
    "   - Si las características están altamente correlacionadas, los valores SHAP pueden ser difíciles de interpretar, ya que las contribuciones se redistribuyen entre las características correlacionadas.\n",
    "\n",
    "3. **Dependencia del modelo**:\n",
    "   - Aunque SHAP es modelo-agnóstico, las simplificaciones necesarias para algunos modelos pueden introducir aproximaciones.\n",
    "\n",
    "\n",
    "#### Aplicaciones Prácticas\n",
    "\n",
    "1. **Detección de sesgos**:\n",
    "   - Identificar si ciertas características están teniendo un impacto desproporcionado en las predicciones del modelo.\n",
    "\n",
    "2. **Medicina personalizada**:\n",
    "   - Explicar qué factores específicos llevaron a una predicción para un paciente individual.\n",
    "\n",
    "3. **Auditoría y cumplimiento**:\n",
    "   - Proporcionar explicaciones claras y justificables de las predicciones para cumplir con regulaciones como el GDPR.\n",
    "\n",
    "\n",
    "#### Casos de Uso Ejemplares\n",
    "\n",
    "1. **Sector financiero**:\n",
    "   - Determinar qué características influyen más en la aprobación de un préstamo o en la predicción de la probabilidad de incumplimiento.\n",
    "\n",
    "2. **Marketing**:\n",
    "   - Analizar qué factores contribuyen más a la probabilidad de que un cliente haga clic en un anuncio.\n",
    "\n",
    "3. **Cuidado de la salud**:\n",
    "   - Evaluar por qué un modelo predijo un diagnóstico específico para un paciente, aumentando la confianza en su uso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **5. Permutation Importance**\n",
    "\n",
    "#### **¿Por qué funciona?**\n",
    "La clave de **Permutation Importance** es que evalúa la relevancia de una característica al observar el impacto de su desorden en el desempeño del modelo. La idea subyacente es simple: si una característica es crucial para el modelo, mezclar sus valores debería interrumpir su capacidad para realizar predicciones precisas. Esto se debe a que la permutación elimina la relación entre esa característica y el objetivo (o salida del modelo). Si, por otro lado, la característica no es importante, alterar sus valores no afectará significativamente el rendimiento.\n",
    "\n",
    "#### **Procedimiento**\n",
    "1. **Evaluar el rendimiento base**: Primero, mide el desempeño del modelo en el conjunto de datos original, por ejemplo, su precisión o error medio cuadrático.\n",
    "2. **Permutar una característica**: Mezcla los valores de una característica en el conjunto de datos, rompiendo la relación entre esa característica y las demás.\n",
    "3. **Medir el nuevo rendimiento**: Evalúa el modelo nuevamente con la característica permutada. \n",
    "4. **Calcular la importancia**: La diferencia entre el desempeño original y el desempeño con la característica permutada refleja la importancia de esa característica. Si el modelo se deteriora significativamente, la característica es importante; si apenas hay cambio, es menos relevante.\n",
    "\n",
    "#### **Ejemplo**  \n",
    "Supón que tienes un modelo para predecir el precio de las casas con características como tamaño, ubicación y número de baños. Si al mezclar los valores de \"tamaño\", el modelo deja de predecir bien los precios, es porque \"tamaño\" es una característica fundamental. Por otro lado, si mezclas los valores de \"número de baños\" y el rendimiento no cambia, puedes concluir que no influye tanto en el resultado.\n",
    "\n",
    "#### **Ventajas y limitaciones**\n",
    "- **Ventajas**: Fácil de implementar, agnóstico al modelo y útil para comparar importancia entre características.\n",
    "- **Limitaciones**: Puede ser lento para conjuntos de datos grandes y, en datos muy correlacionados, puede subestimar la importancia de características relevantes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6. Local Surrogate Models**\n",
    "\n",
    "#### **Resumen**\n",
    "La idea de los modelos surrogados locales es que un modelo complejo puede ser interpretado por un modelo más simple si te enfocas en una región pequeña del espacio de características. Aunque el modelo global (como una red neuronal) sea opaco, su comportamiento en vecindades pequeñas puede aproximarse con algo simple como una regresión lineal o un árbol de decisión. Esto funciona porque las relaciones no lineales a gran escala a menudo se \"suavizan\" cuando miras solo una pequeña sección de los datos.\n",
    "\n",
    "#### **Procedimiento**\n",
    "1. **Selecciona un punto de interés**: Escoge un dato del conjunto que quieras analizar.\n",
    "2. **Crea una vecindad local**: Genera perturbaciones alrededor de ese punto, creando datos similares pero ligeramente diferentes.\n",
    "3. **Obtén predicciones del modelo**: Usa el modelo complejo para predecir las salidas de estas nuevas muestras.\n",
    "4. **Entrena un modelo simple**: Ajusta un modelo interpretable (como una regresión lineal) a las predicciones del modelo complejo dentro de esta vecindad.\n",
    "5. **Extrae explicaciones**: Usa el modelo simple para analizar cómo las características locales influyen en la salida del modelo.\n",
    "\n",
    "#### **Ejemplo**  \n",
    "Imagina que tienes un modelo que predice si un cliente comprará un producto en función de varias características (edad, ingresos, historial de compras, etc.). Si un cliente de 35 años con ingresos de $50,000 toma una decisión, puedes usar un modelo surrogado local para entender cuáles de estas características influyeron más en esa predicción. El modelo surrogado te dirá, por ejemplo, que la edad tuvo más peso que el historial de compras en ese caso particular.\n",
    "\n",
    "#### **Ventajas y limitaciones**\n",
    "- **Ventajas**: Proporciona explicaciones específicas y claras para casos individuales; agnóstico al modelo original.\n",
    "- **Limitaciones**: Las explicaciones son válidas solo localmente, y los resultados pueden variar dependiendo de cómo defines la vecindad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7. Estudio de Ablación en Machine Learning**\n",
    "\n",
    "En muchos casos en Machine Learning, los modelos están formados por múltiples componentes que influyen en el rendimiento total del sistema. Por ello, es muy importante contar con métodos para medir la contribución de cada una de estas partes al modelo en su conjunto. Aquí es donde entra el concepto de **estudio de ablación**.\n",
    "\n",
    "---\n",
    "\n",
    "#### ¿Qué es un Estudio de Ablación?\n",
    "\n",
    "Un **estudio de ablación** consiste en eliminar partes específicas de un modelo para analizar su impacto en el comportamiento general del sistema. Esta técnica permite comprender qué componentes o módulos del modelo son críticos para su rendimiento y cuáles no tienen un impacto significativo.\n",
    "\n",
    "En un estudio de ablación, se investigan las siguientes preguntas:\n",
    "\n",
    "- **¿Qué tan importante es cada parte del modelo para el rendimiento general?**  \n",
    "- **¿Qué componentes son redundantes y pueden ser eliminados sin afectar el comportamiento esperado del modelo?**  \n",
    "- **¿Cómo influyen ciertos módulos individuales en la capacidad de aprendizaje o predicción del modelo?**\n",
    "\n",
    "---\n",
    "\n",
    "#### ¿Por qué es Importante?\n",
    "\n",
    "En un sistema de Machine Learning, generalmente existen múltiples módulos de aprendizaje, como capas en una red neuronal, algoritmos de preprocesamiento, técnicas de regularización, entre otros. Comprender el efecto de cada uno de estos módulos es esencial para:\n",
    "\n",
    "1. **Identificar la importancia relativa de cada componente.**  \n",
    "2. **Optimizar el modelo eliminando elementos redundantes.**  \n",
    "3. **Diagnosticar problemas en el comportamiento del modelo.**  \n",
    "\n",
    "El estudio de ablación es una manera de realizar análisis causal de forma eficiente, con un coste computacional relativamente bajo.\n",
    "\n",
    "---\n",
    "\n",
    "#### Ejemplo: Ablación en Redes Neuronales\n",
    "\n",
    "Por ejemplo, se puede realizar un estudio de ablación en una red neuronal eliminando una o varias capas para estudiar su influencia:\n",
    "\n",
    "1. Se entrena la red con todas las capas y se mide el rendimiento de referencia.  \n",
    "2. Se eliminan una o varias capas de la arquitectura de la red.  \n",
    "3. Se vuelve a entrenar la red y se comparan los resultados con el rendimiento de referencia.\n",
    "\n",
    "Al comparar ambos resultados, es posible determinar si la capa eliminada tiene un impacto significativo en la precisión o en el aprendizaje general.\n",
    "\n",
    "---\n",
    "\n",
    "#### Beneficios del Estudio de Ablación\n",
    "\n",
    "- **Reducción de complejidad computacional.**  \n",
    "- **Comprensión de los efectos causales de los componentes.**  \n",
    "- **Facilita la mejora y optimización del diseño del modelo.**  \n",
    "- **Identificación de componentes críticos y posibles redundancias.**\n",
    "\n",
    "---\n",
    "\n",
    "En conclusión, el **estudio de ablación** es una herramienta poderosa para realizar diagnósticos, optimizar y comprender mejor cómo funciona un modelo de Machine Learning. Se basa en una eliminación sistemática de componentes para analizar su influencia, lo que permite descubrir relaciones causales dentro del diseño de los modelos.\n",
    "La siguiente imagen ilustra este procedimiento:\n",
    "\n",
    "<img src=\"images/ablation_study.png\" alt=\"image\" width=\"auto\" height=\"300\">\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
