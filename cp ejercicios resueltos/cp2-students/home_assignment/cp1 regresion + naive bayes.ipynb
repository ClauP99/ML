{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema: Predicción de precios de viviendas.\n",
    "\n",
    "El dataset `California Housing` es un corpus que contiene información sobre el valor medio del precio de las viviendas unifamiliares en los condados de California. \n",
    "\n",
    "Contiene 20.640 instancias, cada una con 8 características que describen diversos aspectos de la vivienda y su ubicación.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo**: Predecir el precio medio de las viviendas en miles de dólares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cargar el dataset** y comprobar las instancias y características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "cali_housing = fetch_california_housing()\n",
    "cali_housing.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear un DataFrame de Pandas a partir de los datos para visualizar las características.\n",
    "\n",
    "`cali_housing.data` es una matriz NumPy que contiene los valores de las características, y `cali_housing.feature_names` es una lista de los nombres de las características. \n",
    "\n",
    "`cali_housing.target` es una matriz NumPy que contiene los valores objetivo (valor medio de las viviendas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(cali_housing.data, columns=cali_housing.feature_names)\n",
    "df['MedHouseValue'] = cali_housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  MedHouseValue  \n",
       "0        -122.23          4.526  \n",
       "1        -122.22          3.585  \n",
       "2        -122.24          3.521  \n",
       "3        -122.25          3.413  \n",
       "4        -122.25          3.422  \n",
       "...          ...            ...  \n",
       "20635    -121.09          0.781  \n",
       "20636    -121.21          0.771  \n",
       "20637    -121.22          0.923  \n",
       "20638    -121.32          0.847  \n",
       "20639    -121.24          0.894  \n",
       "\n",
       "[20640 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Clasificación o Regresión?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir la matriz de características y el vector de clases en los conjuntos de entrenamiento y prueba. Utilicemos el 70% de los datos para entrenar.\n",
    "\n",
    "Se puede especificar un `random_state` que causa que la división sea determinista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cali_housing.data, cali_housing.target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entrenar el clasificador con los datos extraídos en sklearn, se utiliza la función `fit`. Recibe la matriz y el vector de clase de entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr=LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar el clasificador se pueden utilizar diversas métricas de sklearn que deben depender del problema y el modelo utilizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('Error cuadrático medio:', mse)\n",
    "print('Puntuación R2:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo se puede representar datos complejos, no naturalmente tabulares, para realizar tareas de clasificación o regresión sobre ellos?\n",
    "Por ejemplo: \n",
    "- Dado un audio de 5 segundos clasificar que tipo de sonido es.\n",
    "- Dado una imagen determinar si es de día o de noche.\n",
    "- Dado un texto determinar los sentimientos o emociones en él.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema: Análisis de críticas de cine.\n",
    "\n",
    "El dataset `txt_sentoken` es un corpus de críticas de películas con etiquetas positivas o negativas. \n",
    "\n",
    "Cada elemento del dataset es un objeto `Sentiment` que contiene los siguientes atributos:\n",
    "\n",
    "- `data`: El texto sin procesar de la crítica.\n",
    "- `target`: La etiqueta de sentimiento (0 para negativo y 1 para positivo).\n",
    "  \n",
    "El dataset se organiza en dos carpetas:\n",
    "\n",
    "- `pos`: Contiene archivos que contienen críticas positivas.\n",
    "- `neg`: Contiene archivos que contienen críticas negativas.\n",
    "\n",
    "Cada archivo en estas carpetas representa una crítica individual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo**: Aprender a determinar si una crítica es positiva o negativa basándose en su texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cargar el dataset**: Primeramente cargar los archivos. Luego hacer una lista con los textos extraídos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# directorio con los archivos de críticas positivas\n",
    "path_p = Path(\"data/txt_sentoken/pos\") \n",
    "# directorio con los archivos de críticas negativas\n",
    "path_n = Path(\"data/txt_sentoken/neg\")\n",
    "\n",
    "# listas con el path a cada archivo de los directorios pos y neg\n",
    "ds_p = list(path_p.iterdir()) \n",
    "ds_n = list(path_n.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_file_to_text(file_path: Path) -> str:\n",
    "    with file_path.open('r', encoding='utf-8') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_p = []    # Lista de críticas positivas\n",
    "texts_n = []    # Lista de críticas negativas\n",
    "\n",
    "for file in ds_p:\n",
    "    texts_p.append(convert_file_to_text(file))\n",
    "\n",
    "for file in ds_n:\n",
    "    texts_n.append(convert_file_to_text(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobación de que estén todas las críticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(texts_p), len(texts_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cómo convertimos una cadena de texto en una matriz de características?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede seleccionar varios métodos de vectorizar texto con sklearn. Una de las maneras es `CountVectorizer`, que convierte una colección de documentos en una matriz con recuentos de tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para crear la matriz de características con `CountVectorizer`, se usa su método `fit_transform`. Cada fila de la matriz representa un documento y cada columna representa una palabra única en el corpus. Representa el número de veces que ocurre un término para cada documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts_p + texts_n)\n",
    "Xa = X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de características tiene dos dimensiones, la primera representa la cantidad de instancias (ejemplos) y la segunda la cantidad de características. Busquemos las dimensiones de la matriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matriz de características\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada documento, ¿cuál es el por ciento de términos cuya ocurrencia es distinto de cero? Es decir, ¿cuál es el por ciento de los valores en la matriz que son distintos de cero? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.nnz * 100.0 / (X.shape[0] * X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En clasificación se necesitan los valores correctos para cada instancia del dataset como parte del aprendizaje. \n",
    "\n",
    "Entonces para cada crítica debemos indicar a que clase pertenece. La clase positiva (1) representa una crítica positiva y la clase negativa (0) una crítica negativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [1]*1000 + [0]*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elegir un clasificador\n",
    "\n",
    "El Naive Bayes de sklearn se llama Gaussian Naive Bayes. \n",
    "<!-- porque está diseñado (a diferencia del visto en conferencia) para lidiar con características que sean valores continuos. Gaussian Naive Bayes supone que la probabilidad de las características es gaussiana: $$P(x_i ∣ y)=\\dfrac{1}{\\sqrt{2\\pi \\sigma^2_y}}exp(−\\dfrac{{(x_i-\\mu_y)^2}}{2\\sigma^2_y})$$ -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir la matriz de características y el vector de clases en los conjuntos de entrenamiento y prueba. Utilicemos el 60% de los datos para entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entrenar el clasificador con los datos extraídos en sklearn, se utiliza la función `fit`. Recibe la matriz y el vector de clase de entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "\n",
    "clf.fit(X_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar el clasificador se pueden utilizar las métricas de sklearn como `score`, que evalúa la precisión. Para ello se le da un conjunto de datos a evaluar y el correspondiente vector de clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = clf.score(X_test.toarray(), y_test)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cómo se podrían mejorar los resultados sin cambiar el modelo?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocesamiento del texto**: Limpiar y normalizar el texto (eliminar puntuación, convertir a minúsculas, eliminar stop words, etc.).\n",
    "\n",
    "**Ajustar los hiperparámetros del vectorizador**: Probar diferentes configuraciones de CountVectorizer, como ngram_range, max_features, etc.\n",
    "\n",
    "**Utilizar técnicas de reducción de dimensionalidad**: Aplicar técnicas como PCA (Principal Component Analysis) para reducir la dimensionalidad de los datos.\n",
    "\n",
    "**Aumentar el tamaño del dataset**: Si es posible, agregar más datos para mejorar la capacidad del modelo para generalizar.\n",
    "\n",
    "**Utilizar técnicas de balanceo de clases**: Si las clases están desbalanceadas, utilizar técnicas como sobremuestreo o submuestreo para balancearlas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
