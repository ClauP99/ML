{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import required libraries\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Set random seed\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)        \n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "np.random.seed(42)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv file\n",
    "df = pd.read_csv('data/framingham.csv')\n",
    "\n",
    "print(df.shape)\n",
    "# View top 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize male/female ratio\n",
    "sns.countplot(x=df[\"male\"]).set_title(\"Male/Female Ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the classes distributions\n",
    "sns.countplot(x=df[\"TenYearCHD\"]).set_title(\"Outcome Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the classes distributions by gender\n",
    "sns.countplot(x=\"TenYearCHD\", hue=\"male\", data=df).set_title('Outcome Count by Gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "*Qué podemos aprender de estos gráficos?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any null values\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df.isnull(), cbar=False, cmap=\"viridis\", yticklabels=False)\n",
    "plt.title(\"Null Values in Dataset\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "null_counts = df.isnull().sum()\n",
    "null_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove null values\n",
    "df = df.dropna()\n",
    "\n",
    "# Check if there are any null values\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify features columns\n",
    "X = df.drop(columns=\"TenYearCHD\", axis=0)\n",
    "\n",
    "# Specify target column\n",
    "y = df[\"TenYearCHD\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentación para trabajo con datos desbalanceados: [imbalanced-learn.org](https://imbalanced-learn.org)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required library for resampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Instantiate Random Under Sampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# Perform random under sampling\n",
    "df_data, df_target = rus.fit_resample(X, y)\n",
    "\n",
    "X = df_data\n",
    "y = df_target\n",
    "\n",
    "# Visualize new classes distributions\n",
    "sns.countplot(x = df_target).set_title('Balanced Data Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ventajas de cada clasificador en el contexto de predicción de enfermedades\n",
    "\n",
    "##### 1. Naive Bayes\n",
    "- **Simplicidad y rapidez**: Naive Bayes es fácil de implementar y muy rápido, lo que lo hace adecuado para aplicaciones en tiempo real y grandes volúmenes de datos.\n",
    "- **Manejo de variables categóricas**: Es ideal para trabajar con variables categóricas (por ejemplo, presencia de síntomas, resultados de pruebas) y puede manejar características con distribuciones desconocidas de manera eficiente.\n",
    "- **Poca necesidad de datos**: Puede funcionar bien incluso con pequeños conjuntos de datos, lo que es útil cuando los datos históricos de enfermedades son limitados.\n",
    "- **Probabilidades como salida**: Naive Bayes proporciona una estimación de la probabilidad de pertenencia a cada clase, lo cual es útil para tomar decisiones más informadas en contextos de salud.\n",
    "\n",
    "##### 2. Support Vector Machine (SVM)\n",
    "- **Eficaz en problemas no lineales**: SVM es muy eficaz cuando las clases no son linealmente separables, lo cual es común en los datos médicos, donde los patrones pueden ser complejos.\n",
    "- **Robustez ante el sobreajuste**: SVM busca maximizar el margen entre las clases, lo que hace que el modelo sea menos susceptible al sobreajuste, especialmente en situaciones con características ruidosas.\n",
    "- **Capacidad de trabajar en espacios de alta dimensión**: En medicina, donde pueden existir muchos factores (síntomas, factores genéticos, etc.), SVM es útil para trabajar con datos de alta dimensión sin perder poder de generalización.\n",
    "- **Manejo de marginado pequeño de clases**: Aunque las clases estén desbalanceadas, SVM puede encontrar un margen óptimo para separar las clases, lo que ayuda a mejorar las predicciones.\n",
    "\n",
    "##### 3. Árbol de Decisión\n",
    "- **Interpretabilidad**: Los árboles de decisión son fáciles de interpretar y entender, lo cual es crucial en un contexto médico donde los profesionales necesitan saber cómo se llegó a una conclusión.\n",
    "- **No requiere preprocesamiento complejo**: Los árboles de decisión no requieren que los datos estén normalizados o estandarizados, lo que simplifica el proceso de preparación de los datos.\n",
    "- **Flexibilidad**: Los árboles de decisión pueden capturar patrones complejos, lo que permite representar de manera eficaz situaciones complejas en el diagnóstico de enfermedades.\n",
    "\n",
    "##### 4. Regresión Logística\n",
    "- **Simplicidad y eficiencia**: La regresión logística es simple de implementar, rápida de entrenar y generalmente eficiente, lo que la hace adecuada para modelos en tiempo real en el diagnóstico de enfermedades.\n",
    "- **Probabilidades como salida**: Al igual que Naive Bayes, la regresión logística también proporciona probabilidades, lo que permite una toma de decisiones más informada y basada en la confianza del modelo en su predicción.\n",
    "- **Fácil de interpretar**: Los coeficientes de la regresión logística son relativamente fáciles de interpretar, lo que facilita entender el impacto de cada característica en la predicción del diagnóstico.\n",
    "- **Eficiencia en problemas lineales**: Si las relaciones entre las características y la clase son lineales (o casi lineales), la regresión logística puede ser muy eficaz y producir buenos resultados rápidamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for machine learning classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Instantiate the machine learning classifiers\n",
    "log_model = LogisticRegression(max_iter=10000)\n",
    "svc_model = LinearSVC(dual=False)\n",
    "dtr_model = DecisionTreeClassifier()\n",
    "gnb_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for performance metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define dictionary with performance metrics\n",
    "scoring = {'accuracy':accuracy_score, \n",
    "           'precision':precision_score,\n",
    "           'recall':recall_score, \n",
    "           'f1_score':f1_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train, validation, and test sets\n",
    "test_size=0.2 \n",
    "val_size=0.25\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of models to evaluate\n",
    "models = {\n",
    "    'Logistic Regression': log_model, \n",
    "    'Support Vector Classifier': svc_model,\n",
    "    'Decision Tree': dtr_model,\n",
    "    'Gaussian Naive Bayes': gnb_model\n",
    "}\n",
    "\n",
    "scores = {name: [] for name in (['Model', 'Dataset'] + list(scoring.keys()))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each model\n",
    "for name, model in models.items():\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    scores['Model'].extend([name, name])\n",
    "    scores['Dataset'].extend(['Training', 'Validation'])\n",
    "\n",
    "    train_pred = model.predict(X_train)\n",
    "    val_pred = model.predict(X_val)\n",
    "\n",
    "    for m_name, metric in scoring.items():\n",
    "        scores[m_name].append(metric(y_train, train_pred))  # Compute metrics on training set\n",
    "        scores[m_name].append(metric(y_val, val_pred))      # Compute metrics on validation set\n",
    "\n",
    "# Create DataFrame with training and validation scores\n",
    "models_scores_table = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_scores_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [i for i in range(1,len(models.items())+1)]\n",
    "idx_train = [i for i in range(0,len(models_scores_table['Model']), 2)]\n",
    "idx_val = [i for i in range(1,len(models_scores_table['Model']),  2)]\n",
    "\n",
    "for i in range(1, len(scoring.keys())):\n",
    "    m_name = list(scoring.keys())[i]\n",
    "    plt.plot(idx, 0.1*i+models_scores_table[m_name][idx_train]  ,marker='o' , label = m_name )\n",
    "\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Metrics\")\n",
    "plt.title(\"Comparison of Different Classifiers\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for each classifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "for name ,clf in models.items():\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(clf, X_val, y_val, cmap=plt.cm.Blues)\n",
    "    plt.title(name)\n",
    "    #plt.savefig(f\"{name}_confusion_matrix_seed_{seed}.png\", dpi=1000)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factores que pueden afectar negativamente a cada clasificador\n",
    "\n",
    "##### 1. Naive Bayes\n",
    "- **Dependencia de las características**: Naive Bayes supone que las características son independientes, lo cual es raramente cierto en datos médicos. Si las características están correlacionadas, el modelo puede tener un desempeño subóptimo.\n",
    "- **Distribución de los datos**: Supone que las características siguen una distribución específica (por ejemplo, gaussiana). Si los datos no cumplen con estas distribuciones, el modelo podría fallar.\n",
    "- **Sensibilidad ruido**: Naive Bayes puede verse afectado si existen características irrelevantes en el conjunto de datos, lo que podría llevar a predicciones incorrectas si no se realiza una selección de características adecuada.\n",
    "\n",
    "\n",
    "##### 2. Support Vector Machine (SVM)\n",
    "- **Elección incorrecta de kernel**: La selección de un kernel inapropiado puede llevar a un sobreajuste o un subajuste del modelo, afectando su capacidad de generalización.\n",
    "- **Datos no lineales sin kernel adecuado**: Si los datos no son linealmente separables y no se usa un kernel adecuado, el modelo no podrá encontrar una buena frontera de decisión.\n",
    "- **Hiperparámetros mal ajustados**: El parámetro `C` controla el equilibrio entre maximizar el margen y minimizar los errores de clasificación. Si `C` es demasiado pequeño o grande, puede llevar a un mal rendimiento. Un ajuste incorrecto de `C` puede resultar en sobreajuste o subajuste.\n",
    "\n",
    "##### 3. Árbol de Decisión\n",
    "- **Sobreajuste**: Los árboles de decisión tienden a sobreajustarse a los datos de entrenamiento si no se podan adecuadamente. Esto ocurre cuando el árbol se vuelve muy complejo y captura el ruido en lugar de las tendencias generales.\n",
    "- **Sensibilidad a pequeñas variaciones en los datos**: Un cambio pequeño en los datos de entrenamiento puede causar grandes cambios en la estructura del árbol, lo que lo hace inestable.\n",
    "- **Escalabilidad en árboles profundos**: A medida que el árbol crece, su interpretación y eficiencia pueden deteriorarse, especialmente con muchas características como en este dataset.\n",
    "\n",
    "\n",
    "##### 4. Regresión Logística\n",
    "- **Relación no lineal entre características y clase**: La regresión logística asume que la relación entre las características y la clase es lineal. Si la relación es no lineal, el modelo no funcionará bien sin transformaciones adicionales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ahora es tu turno!!!**\n",
    "\n",
    "Intenta mejorar los clasificadores para resolver el problema en cuestión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos Naive Bayes supone que las características son independientes para solucionar este problema podemos usar técnicas de selección de características como correlación o reducción de dimensionalidad (PCA) para identificar y eliminar características redundantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=5)  # Reducir a 5 componentes principales\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En SVM podemos usar Cross Validation para probar diferentes kernels como 'linear', 'rbf', y 'poly' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'kernel': ['linear', 'rbf', 'poly'], 'C': [0.1, 1, 10]}\n",
    "grid = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Mejor kernel: {grid.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Árboles de Decisión podemos fijar una profundidad máxima y un mínimo de muestras por nodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=5, min_samples_split=10)\n",
    "tree.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Regresión logística podemos usar la regresión Lasso o Ridge para evitar sobreajuste"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
